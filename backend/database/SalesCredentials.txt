IP :139.144.56.127
port: 631(Putty/winscp)
login as user :ubuntu
password : oon5at1aeNg#oo^@#78#$ 
su-
enter root server pwd new : San_!@#SHM!@#5986@^&875#qwe
root passwordnew : San_!@#SHHAM!@#5986@^&875#qwe%^&DRT
rootpassNew : San_!@#SHHAM!@#5986@^&875#qwe%^&DRT@$&QW

DISABLE_ESLINT_PLUGIN=true npm run build

sudo ufw allow from 1152.58.131.211 to any port 9200 proto tcp
DB url : http://139.144.56.127:8080/phpmyadmin/index.php?route=/&route=%2F
user :pmauser 
password : gdftWAD$%^@09!
Root DB Password------
San_!@#190$^160*%$
use : dataPB2B

frontend URL : http://139.144.56.127:3000/
backend URL :http://139.144.56.127:5000

SMTP_USER=salesdream09@gmail.com
SMTP password : mzfo nvby cphn acts
SMTP_USER=admin@salesdream.com
SMTP_PASS=rrhy thvz gmim kaiz


New Email:
Sales Dream
admin@salesdream.com
I)0L2\s<3s>>z0EGU!"


$2a$10$O.DVUfOq2Jr5iWHTv.2NO.ffq9MSoVk5EleITxXg32BqVWnf7uCG2
cd /home/ubuntu/pyspark_jobs/jobs

lsof -i :3000
sudo kill -9 id

ETL_0190.py


after insertion of 1 state ---------------------------------------------------
curl -sS -X POST "http://127.0.0.1:9200/merged_index_v1/_refresh" 
curl -sS "http://127.0.0.1:9200/merged_index_v1/_count?pretty"
curl -sS -X GET "http://127.0.0.1:9200/merged_index_v1/_search?size=5&pretty"
cd /home/ubuntu/pyspark_jobs/jobs
----very imp change state at 3 places---------------change state name 
--basic coamamnds clear  -- it will clear screen
nohup /home/ubuntu/spark/spark-3.5.1-bin-hadoop3/bin/spark-submit \
  --master local[*] \
  --packages com.mysql:mysql-connector-j:8.0.33,org.opensearch.client:opensearch-spark-30_2.12:1.3.0 \
  --driver-memory 12g \
  /home/ubuntu/pyspark_jobs/jobs/ETL_0190.py \
  --jdbc-url "jdbc:mysql://127.0.0.1:3306/dataPB2B?useSSL=false&serverTimezone=UTC" \
  --jdbc-user spark_user \
  --jdbc-pass "NewStrongPasswordHere" \
  --people-table tbl_linked_in_final_usa \
  --company-table tbl_merged_usa_data \
  --state CA \
  --state-column normalized_state \
  --fetchsize 2000 \
  --partition-column id \
  --num-partitions 8 \
  --opensearch-nodes 127.0.0.1 \
  --opensearch-port 9200 \
  --opensearch-index merged_index_v1 \
  --opensearch-wan-only \
  --sample-size 0 \
  > /home/ubuntu/pyspark_jobs/jobs/logs/etl_merged_linkedin_CA.full.out 2>&1 &
tail -f /home/ubuntu/pyspark_jobs/jobs/logs/etl_merged_linkedin_CA.full.out
cehck this at the end of logs  Write completed successfully. Stopping Spark.
ps -ef | grep spark
to connect db from command line 
su-
enter root server pwd :
San_!@#SHHAM!@#5986@^&875#qwe%^&DRT
mysql -u root -p
pwd : San_!@#190$^160*%$
UBUNTu :: 
oon5at1aeNg#oo^@#78#$
how to check open search is working or not
ps aux | grep opensearch
if not showing hen restart
go to cd /home/ubuntu/opensearch-2.13.0
then run below comamnd
nohup ./opensearch-tar-install.sh > opensearch.log 2>&1 &

aptche fix
 sudo ufw status numbered
[ 1] Allow from 203.0.113.45 to any port 8080 proto tcp
[ 2] DENY 8080/tcp
[ 3] ALLOW 80/tcp
Delete the old allow rule by its number (say [1]):
sudo ufw delete 1
Add 
sudo ufw insert 1 allow from 152.59.183.194 to any port 8080 proto tcp
Confirm
sudo ufw status numbered

sudo ufw allow from 152.59.183.194 to any port 9200 proto tcp
sudo ufw delete allow 9200/tcp




sudo ufw allow from 203.0.113.45 to any port 9200 proto tcp


eneter your IP above


sudo ufw status

Later, if your IP changes

sudo ufw delete allow from OLD_IP to any port 9200 proto tcp
sudo ufw allow from NEW_IP to any port 9200 proto tcp

Then check:

sudo ufw status